CPU: AMD Ryzen Threadripper PRO 3945WX 12-Cores
OS: Ubuntu_24.04.3_LTS
Date (UTC): 2025-12-31 00:00:00 UTC+0000
------------------------
========================================================================
Fused vs Unpacked Ternary Computation Benchmark
HyperFold Technologies UK Ltd.
========================================================================

Architecture: x86_64 with AVX2 support
Configuration:
  Matrix Size:  4096 × 4096
  Total Weights: 16777216
  Sparsity:     50%
  Iterations:   50

Memory Footprint:
  8-bit representation: 16384 KB
  2-bit representation: 4096 KB (75.0% reduction)

========================================================================
TEST 1: BASELINE (8-bit Standard)
========================================================================
Method: 8-bit int8_t -> standard integer multiplication
Running...
Total Time:     2970.65 ms
Time per Iter:  59.413 ms
Throughput:     0.56 GFLOPS

========================================================================
TEST 2: 2-BIT WITH UNPACKING (Decode Then Compute)
========================================================================
Method: 2-bit packed -> unpack to array -> standard multiplication
Running...
Total Time:     3500.90 ms
Time per Iter:  70.018 ms
Throughput:     0.48 GFLOPS
vs Baseline:    0.85x

========================================================================
TEST 3: FUSED KERNEL (2-bit Packed + Fused Decode-Compute)
========================================================================
Method: 2-bit packed -> direct computation without full unpacking
Optimizations:
  1. 2-bit packed encoding (75% memory reduction)
  2. Fused decode-compute (no temporary array)
Running...
Total Time:     2837.78 ms
Time per Iter:  56.756 ms
Throughput:     0.59 GFLOPS
vs Baseline:    1.05x
vs Unpacked:    1.23x

========================================================================
TEST 4: FUSED KERNEL WITH SIMD
========================================================================
Method: Architecture-optimized SIMD implementation
  Using: x86_64 AVX2 (8 elements per vector)
Running...
Total Time:     340.05 ms
Time per Iter:  6.801 ms
Throughput:     4.93 GFLOPS
vs Baseline:    8.74x
vs Fused:       8.35x

========================================================================
VERIFICATION (Tests 1-3)
========================================================================
✓ All outputs match (within epsilon=1e-3)

========================================================================
TEST 5: FUSED + SPARSE CSR (All Three Optimizations)
========================================================================
Testing with 70% sparsity to demonstrate CSR advantage...
  Sparsity: 70%
  Sparse CSR memory: 15569 KB (380.1% of 2-bit dense)
  Non-zero packed bytes: 3185310 / 4194304 (24.1% reduction)

Optimizations:
  1. 2-bit packed encoding (75% memory reduction)
  2. Fused decode-compute (no temporary array)
  3. Sparse CSR format (skip zero-only packed bytes)
Running...
Total Time:     1699.02 ms
Time per Iter:  33.980 ms
Throughput:     0.99 GFLOPS
vs Baseline:    1.75x
vs Test 3:      1.67x

========================================================================
SUMMARY
========================================================================

Method                              |    Time (ms) |  Memory (KB) |      Speedup |     GFLOPS
-------------------------------------------------------------------------------------------
Test 1: Baseline (8-bit)            |      2970.65 |        16384 |       1.00× |       0.56
Test 2: 2-bit Unpacked              |      3500.90 |         4096 |         0.85x |       0.48
Test 3: Fused (2-bit+Fusion)        |      2837.78 |         4096 |         1.05x |       0.59
Test 4: Fused+SIMD                  |       340.05 |         4096 |         8.74x |       4.93
Test 5: Fused+CSR (70%% sparse)     |      1699.02 |        15569 |         1.75x |       0.99

Key Comparisons:
  Test 3 vs Test 2 (Fusion advantage):    1.23x speedup
  Test 4 vs Test 3 (SIMD advantage):      8.35x speedup
  Test 5 vs Test 3 (CSR advantage):       1.67x speedup
  Test 5 vs Baseline (Combined):          1.75x speedup

========================================================================
CONCLUSION
========================================================================

✓ MULTI-ARCHITECTURE OPTIMIZATIONS DEMONSTRATED

1. FUSION ADVANTAGE (Test 3 vs Test 2): 1.23x
   Fused decode-compute eliminates unpacking overhead

2. AVX2 SIMD ADVANTAGE (Test 4 vs Test 3): 8.35x
   x86_64 AVX2 processes 8 elements per vector

3. SPARSE CSR ADVANTAGE (Test 5 vs Test 3): 1.67x
   At 70% sparsity, CSR format skips zero-only packed bytes

✓ SIMD PERFORMANCE GAIN: 8.74x over baseline

This benchmark proves that efficient ternary computation requires
layered optimizations: memory reduction, fused operations, and
architecture-specific vectorization working together.
